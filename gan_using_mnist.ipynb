{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Read the dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data from mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrimator definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    # First convolutional and pool layers\n",
    "    # This finds 32 different 5 x 5 pixel features\n",
    "    d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "    d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d1 = d1 + d_b1\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Second convolutional and pool layers\n",
    "    # This finds 64 different 5 x 5 pixel features\n",
    "    d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "    d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d2 = d2 + d_b2\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # First fully connected layer\n",
    "    d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "\n",
    "    # Second fully connected layer\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "    o = tf.sigmoid(d4)\n",
    "    \n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim):\n",
    "    # From z_dim to 56*56 dimension\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    o = tf.nn.tanh(g4)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_fig(imgs, path, w = 14, h = 14, fig_size=(14, 14), columns = 4, rows = 5):\n",
    "    assert len(imgs) == columns * rows, \"Please check the images\"\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    for i in range(0, columns*rows):\n",
    "        img = imgs[i]\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        if img.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(img)\n",
    "    plt.savefig(path)\n",
    "\n",
    "\n",
    "def frames_to_gif(directory, output_path=\"./output.gif\"):\n",
    "    assert os.path.isdir(directory), \"Please make sure {} is a folder, and contains images\".format(directory)\n",
    "    images = []\n",
    "    files = os.listdir(directory)\n",
    "    ordered_files = sorted(files, key=lambda x: (int(re.sub('\\D','',x)),x))\n",
    "    for filename in ordered_files:\n",
    "        path = os.path.join(directory, filename)\n",
    "        images.append(imageio.imread(path))\n",
    "    imageio.mimsave(output_path, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define variable scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dimensions = 100\n",
    "batch_size = 64\n",
    "tf.reset_default_graph()\n",
    "# network: generator\n",
    "with tf.variable_scope(\"G\"):\n",
    "    z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder') \n",
    "    # z_placeholder is for feeding input noise to the generator\n",
    "    Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "    # Gz holds the generated images\n",
    "\n",
    "# network: discriminator\n",
    "with tf.variable_scope(\"D\"):\n",
    "    x_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name='x_placeholder') \n",
    "    # x_placeholder is for feeding input images to the discriminator\n",
    "    Dx = discriminator(x_placeholder) \n",
    "    # Dx will hold discriminator prediction probabilities\n",
    "    # for the real MNIST images\n",
    "    Dg = discriminator(Gz, reuse=True)\n",
    "    # Dg will hold discriminator prediction probabilities for generated images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-2\n",
    "# loss for each network\n",
    "# maximize 1/m * Σlog(Dx) + 1/m * Σ(1-Dg) = min - 1/m * Σlog(Dx) - 1/m * Σ(1-Dg)\n",
    "D_loss = tf.reduce_mean(-tf.log(Dx + eps) - tf.log(1 - Dg + eps))\n",
    "G_loss = tf.reduce_mean(-tf.log(Dg + eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the variables for different network\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "# Train the discriminator\n",
    "d_trainer = tf.train.GradientDescentOptimizer(0.0001).minimize(D_loss, var_list=d_vars)\n",
    "\n",
    "# Train the generator\n",
    "g_trainer = tf.train.GradientDescentOptimizer(0.0001).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# results save folder\n",
    "if not os.path.isdir('MNIST_GAN_results'):\n",
    "    os.mkdir('MNIST_GAN_results')\n",
    "\n",
    "# initial 20 random noise images\n",
    "target_init_z = np.random.normal(0, 1, size=[20, z_dimensions])\n",
    "train_set = (mnist.train.images - 0.5) / 0.5  # normalization; range: -1 ~ 1\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# trainign stats\n",
    "train_hist = {}\n",
    "train_hist['D_losses'] = []\n",
    "train_hist['G_losses'] = []\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "epochs = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train generator and discriminator together\n",
    "for i in tqdm(range(epochs)):\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    for iteration in range(train_set.shape[0] // batch_size):\n",
    "        with tf.variable_scope(\"D\"):\n",
    "            real_image_batch = train_set[iteration*batch_size:(iteration+1)*batch_size].reshape([batch_size, 28, 28, 1])\n",
    "            z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "            \n",
    "            # Train discriminator\n",
    "            _, d_loss = sess.run([d_trainer, D_loss],\n",
    "                                    {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "            D_losses.append(d_loss)\n",
    "            \n",
    "            # Train generator\n",
    "            z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "            _, g_loss = sess.run([g_trainer, G_loss], feed_dict={z_placeholder: z_batch})\n",
    "            G_losses.append(g_loss)\n",
    "    train_hist['D_losses'].append(np.mean(D_losses))\n",
    "    train_hist['G_losses'].append(np.mean(G_losses))\n",
    "    if i % 50 == 0:\n",
    "        # show generated images\n",
    "        with tf.variable_scope(\"G\"):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            generated_images = generator(z_placeholder, target_init_z.shape[0], z_dimensions)\n",
    "            images = sess.run(generated_images, {z_placeholder: target_init_z})\n",
    "            path = os.path.join(\"MNIST_GAN_results\", \"epoch_{}.jpg\".format(i))\n",
    "            save_fig(images.squeeze(), path)\n",
    "        print(\"Mean Loss for Discriminator:{}, Mean Loss for Generator: {}\".format(np.mean(D_losses), np.mean(G_losses)))\n",
    "saver.save(sess, \"./model/model.ckpt\")\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames_to_gif(\"MNIST_GAN_results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./loss.pkl', 'wb') as f:\n",
    "    pickle.dump(train_hist, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

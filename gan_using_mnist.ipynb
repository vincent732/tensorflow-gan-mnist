{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all the necessary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/amacs/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "# Read the dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import imageio\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read data from mnist dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrimator definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(images, reuse=False):\n",
    "    if reuse:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "\n",
    "    # First convolutional and pool layers\n",
    "    # This finds 32 different 5 x 5 pixel features\n",
    "    d_w1 = tf.get_variable('d_w1', [5, 5, 1, 32], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b1 = tf.get_variable('d_b1', [32], initializer=tf.constant_initializer(0))\n",
    "    d1 = tf.nn.conv2d(input=images, filter=d_w1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d1 = d1 + d_b1\n",
    "    d1 = tf.nn.relu(d1)\n",
    "    d1 = tf.nn.avg_pool(d1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # Second convolutional and pool layers\n",
    "    # This finds 64 different 5 x 5 pixel features\n",
    "    d_w2 = tf.get_variable('d_w2', [5, 5, 32, 64], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b2 = tf.get_variable('d_b2', [64], initializer=tf.constant_initializer(0))\n",
    "    d2 = tf.nn.conv2d(input=d1, filter=d_w2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    d2 = d2 + d_b2\n",
    "    d2 = tf.nn.relu(d2)\n",
    "    d2 = tf.nn.avg_pool(d2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "    # First fully connected layer\n",
    "    d_w3 = tf.get_variable('d_w3', [7 * 7 * 64, 1024], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b3 = tf.get_variable('d_b3', [1024], initializer=tf.constant_initializer(0))\n",
    "    d3 = tf.reshape(d2, [-1, 7 * 7 * 64])\n",
    "    d3 = tf.matmul(d3, d_w3)\n",
    "    d3 = d3 + d_b3\n",
    "    d3 = tf.nn.relu(d3)\n",
    "\n",
    "    # Second fully connected layer\n",
    "    d_w4 = tf.get_variable('d_w4', [1024, 1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    d_b4 = tf.get_variable('d_b4', [1], initializer=tf.constant_initializer(0))\n",
    "    d4 = tf.matmul(d3, d_w4) + d_b4\n",
    "    o = tf.sigmoid(d4)\n",
    "    \n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, batch_size, z_dim):\n",
    "    # From z_dim to 56*56 dimension\n",
    "    g_w1 = tf.get_variable('g_w1', [z_dim, 3136], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b1 = tf.get_variable('g_b1', [3136], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g1 = tf.matmul(z, g_w1) + g_b1\n",
    "    g1 = tf.reshape(g1, [-1, 56, 56, 1])\n",
    "    g1 = tf.contrib.layers.batch_norm(g1, epsilon=1e-5, scope='bn1')\n",
    "    g1 = tf.nn.relu(g1)\n",
    "\n",
    "    # Generate 50 features\n",
    "    g_w2 = tf.get_variable('g_w2', [3, 3, 1, z_dim/2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b2 = tf.get_variable('g_b2', [z_dim/2], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g2 = tf.nn.conv2d(g1, g_w2, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g2 = g2 + g_b2\n",
    "    g2 = tf.contrib.layers.batch_norm(g2, epsilon=1e-5, scope='bn2')\n",
    "    g2 = tf.nn.relu(g2)\n",
    "    g2 = tf.image.resize_images(g2, [56, 56])\n",
    "\n",
    "    # Generate 25 features\n",
    "    g_w3 = tf.get_variable('g_w3', [3, 3, z_dim/2, z_dim/4], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b3 = tf.get_variable('g_b3', [z_dim/4], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g3 = tf.nn.conv2d(g2, g_w3, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g3 = g3 + g_b3\n",
    "    g3 = tf.contrib.layers.batch_norm(g3, epsilon=1e-5, scope='bn3')\n",
    "    g3 = tf.nn.relu(g3)\n",
    "    g3 = tf.image.resize_images(g3, [56, 56])\n",
    "\n",
    "    # Final convolution with one output channel\n",
    "    g_w4 = tf.get_variable('g_w4', [1, 1, z_dim/4, 1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g_b4 = tf.get_variable('g_b4', [1], initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "    g4 = tf.nn.conv2d(g3, g_w4, strides=[1, 2, 2, 1], padding='SAME')\n",
    "    g4 = g4 + g_b4\n",
    "    o = tf.nn.tanh(g4)\n",
    "    return o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_fig(imgs, path, w = 14, h = 14, fig_size=(14, 14), columns = 4, rows = 5):\n",
    "    assert len(imgs) == columns * rows, \"Please check the images\"\n",
    "    fig = plt.figure(figsize=fig_size)\n",
    "    for i in range(0, columns*rows):\n",
    "        img = imgs[i]\n",
    "        fig.add_subplot(rows, columns, i+1)\n",
    "        if img.ndim == 2:\n",
    "            plt.gray()\n",
    "        plt.imshow(img)\n",
    "    plt.savefig(path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def frames_to_gif(directory, output_path=\"./output.gif\"):\n",
    "    assert os.path.isdir(directory), \"Please make sure {} is a folder, and contains images\".format(directory)\n",
    "    images = []\n",
    "    files = os.listdir(directory)\n",
    "    ordered_files = sorted(files, key=lambda x: (int(re.sub('\\D','',x)),x))\n",
    "    for filename in ordered_files:\n",
    "        path = os.path.join(directory, filename)\n",
    "        images.append(imageio.imread(path))\n",
    "    imageio.mimsave(output_path, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define variable scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "z_dimensions = 100\n",
    "batch_size = 64\n",
    "tf.reset_default_graph()\n",
    "# network: generator\n",
    "with tf.variable_scope(\"G\"):\n",
    "    z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder') \n",
    "    # z_placeholder is for feeding input noise to the generator\n",
    "    Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "    # Gz holds the generated images\n",
    "\n",
    "# network: discriminator\n",
    "with tf.variable_scope(\"D\"):\n",
    "    x_placeholder = tf.placeholder(tf.float32, shape = [None,28,28,1], name='x_placeholder') \n",
    "    # x_placeholder is for feeding input images to the discriminator\n",
    "    Dx = discriminator(x_placeholder) \n",
    "    # Dx will hold discriminator prediction probabilities\n",
    "    # for the real MNIST images\n",
    "    Dg = discriminator(Gz, reuse=True)\n",
    "    # Dg will hold discriminator prediction probabilities for generated images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eps = 1e-2\n",
    "# loss for each network\n",
    "# maximize 1/m * Σlog(Dx) + 1/m * Σ(1-Dg) = min - 1/m * Σlog(Dx) - 1/m * Σ(1-Dg)\n",
    "D_loss = tf.reduce_mean(-tf.log(Dx + eps) - tf.log(1 - Dg + eps))\n",
    "G_loss = tf.reduce_mean(-tf.log(Dg + eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get the variables for different network\n",
    "tvars = tf.trainable_variables()\n",
    "\n",
    "d_vars = [var for var in tvars if 'd_' in var.name]\n",
    "g_vars = [var for var in tvars if 'g_' in var.name]\n",
    "\n",
    "# Train the discriminator\n",
    "d_trainer = tf.train.GradientDescentOptimizer(0.0001).minimize(D_loss, var_list=d_vars)\n",
    "\n",
    "# Train the generator\n",
    "g_trainer = tf.train.GradientDescentOptimizer(0.0001).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_directory = \"./MNIST_GAN_results_1000\"\n",
    "# results save folder\n",
    "if not os.path.isdir(output_directory):\n",
    "    os.mkdir(output_directory)\n",
    "\n",
    "# initial 20 random noise images\n",
    "target_init_z = np.random.normal(0, 1, size=[20, z_dimensions])\n",
    "train_set = (mnist.train.images - 0.5) / 0.5  # normalization; range: -1 ~ 1\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# trainign stats\n",
    "train_hist = {}\n",
    "train_hist['D_losses'] = []\n",
    "train_hist['G_losses'] = []\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 50/1000 [15:54<5:13:48, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:1.0402277708053589, Mean Loss for Generator: 0.9459400177001953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 100/1000 [31:58<4:56:04, 19.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.7283501625061035, Mean Loss for Generator: 1.5389714241027832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 150/1000 [48:03<4:39:15, 19.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.6780683994293213, Mean Loss for Generator: 1.612345814704895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 200/1000 [1:04:06<4:22:21, 19.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.6808307766914368, Mean Loss for Generator: 1.628017544746399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 250/1000 [1:20:07<4:05:57, 19.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.7264381647109985, Mean Loss for Generator: 1.5976718664169312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 300/1000 [1:36:06<3:48:48, 19.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.7153699994087219, Mean Loss for Generator: 1.6504563093185425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 350/1000 [1:52:05<3:32:23, 19.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.6555188298225403, Mean Loss for Generator: 1.7506763935089111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 400/1000 [2:08:01<3:15:17, 19.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.6107269525527954, Mean Loss for Generator: 1.849137544631958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 450/1000 [2:23:58<2:59:01, 19.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.5802996158599854, Mean Loss for Generator: 1.9737799167633057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 500/1000 [2:39:52<2:42:49, 19.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.5433701872825623, Mean Loss for Generator: 2.050025701522827\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 550/1000 [2:55:46<2:26:16, 19.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.5019587874412537, Mean Loss for Generator: 2.146402359008789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 600/1000 [3:11:39<2:09:45, 19.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.48456451296806335, Mean Loss for Generator: 2.187883138656616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 650/1000 [3:27:31<1:53:38, 19.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.45798495411872864, Mean Loss for Generator: 2.2328341007232666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 700/1000 [3:43:23<1:37:14, 19.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.43298688530921936, Mean Loss for Generator: 2.303063154220581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 750/1000 [3:59:14<1:21:00, 19.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.4218542277812958, Mean Loss for Generator: 2.3747763633728027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 800/1000 [4:15:04<1:04:44, 19.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.4027394950389862, Mean Loss for Generator: 2.411433458328247\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 850/1000 [4:30:55<48:32, 19.42s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.3920406401157379, Mean Loss for Generator: 2.4680192470550537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 900/1000 [4:46:45<32:26, 19.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.376052588224411, Mean Loss for Generator: 2.5101349353790283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 950/1000 [5:02:35<16:09, 19.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.35777920484542847, Mean Loss for Generator: 2.533843517303467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [5:18:24<00:00, 19.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Loss for Discriminator:0.3599212169647217, Mean Loss for Generator: 2.515031337738037\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train generator and discriminator together\n",
    "for i in tqdm(range(1, epochs+1)):\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    for iteration in range(train_set.shape[0] // batch_size):\n",
    "        with tf.variable_scope(\"D\"):\n",
    "            real_image_batch = train_set[iteration*batch_size:(iteration+1)*batch_size].reshape([batch_size, 28, 28, 1])\n",
    "            z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "            \n",
    "            # Train discriminator\n",
    "            _, d_loss = sess.run([d_trainer, D_loss],\n",
    "                                    {x_placeholder: real_image_batch, z_placeholder: z_batch})\n",
    "            D_losses.append(d_loss)\n",
    "            \n",
    "            # Train generator\n",
    "            z_batch = np.random.normal(0, 1, size=[batch_size, z_dimensions])\n",
    "            _, g_loss = sess.run([g_trainer, G_loss], feed_dict={z_placeholder: z_batch})\n",
    "            G_losses.append(g_loss)\n",
    "    train_hist['D_losses'].append(np.mean(D_losses))\n",
    "    train_hist['G_losses'].append(np.mean(G_losses))\n",
    "    if i % 50 == 0:\n",
    "        # show generated images\n",
    "        with tf.variable_scope(\"G\"):\n",
    "            tf.get_variable_scope().reuse_variables()\n",
    "            generated_images = generator(z_placeholder, target_init_z.shape[0], z_dimensions)\n",
    "            images = sess.run(generated_images, {z_placeholder: target_init_z})\n",
    "            path = os.path.join(output_directory, \"epoch_{}.jpg\".format(i))\n",
    "            save_fig(images.squeeze(), path)\n",
    "        print(\"Mean Loss for Discriminator:{}, Mean Loss for Generator: {}\".format(np.mean(D_losses), np.mean(G_losses)))\n",
    "saver.save(sess, \"./model_1000/model.ckpt\")\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "frames_to_gif(\"MNIST_GAN_results_1000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.Session(config=config)\n",
    "sess.run(tf.global_variables_initializer())\n",
    "z_dimensions = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "with tf.variable_scope(\"G\"):\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    z_placeholder = tf.placeholder(tf.float32, [None, z_dimensions], name='z_placeholder') \n",
    "    # z_placeholder is for feeding input noise to the generator\n",
    "    Gz = generator(z_placeholder, batch_size, z_dimensions) \n",
    "    # Gz holds the generated images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./model_1000/model.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver.restore(sess, './model_1000/model.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff64cb87128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_z = np.random.normal(0, 1, size=[1, z_dimensions])\n",
    "with tf.variable_scope(\"G\"):\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    images = sess.run(Gz, {z_placeholder: test_z})\n",
    "    plt.imshow(images[0].squeeze(), cmap ='gray')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
